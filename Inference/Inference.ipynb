{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video Model Inference",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3dP-FrZKKtf"
      },
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlXDZSA6KOYI"
      },
      "source": [
        "### Load video clip for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYFGT_zAKbV_"
      },
      "source": [
        "image_dims = (100, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI27FqHCKetv"
      },
      "source": [
        "# Get the video path\n",
        "sample_path = os.path.relpath('<Relative path to video sample>')\n",
        "\n",
        "# Get video from path\n",
        "cap = cv2.VideoCapture(sample_path)\n",
        "\n",
        "frames16 = []\n",
        "X = [] # Input samples list\n",
        "\n",
        "counter = 0\n",
        "\n",
        "while(cap.isOpened()) and counter != 161:\n",
        "    # Store one sample (of 16 frames)\n",
        "    if counter % 16 == 0 and counter != 0:\n",
        "        X.append(frames16)\n",
        "        # Reset frames16\n",
        "        frames16 = []\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    # Check if a frame is capture\n",
        "    if ret:\n",
        "        # Resize the frame to image_dims x 3\n",
        "        frame = cv2.resize(frame, image_dims, interpolation=cv2.INTER_CUBIC)\n",
        "        # Store the frame in a list\n",
        "        frames16.append(frame)\n",
        "    else:\n",
        "        break\n",
        "    counter += 1\n",
        "\n",
        "# Release everything when job is finished\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJQbIe8kN4mh"
      },
      "source": [
        "X = np.array(X, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2eGHqZ7N_mn"
      },
      "source": [
        "# Max normalize input\n",
        "X = X / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ap3gwm5rcbx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98aedfcd-e0bd-4092-9c0a-6e712b2ddf03"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 16, 100, 100, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smq0hrvTNzWr"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvlguHDOrfVa"
      },
      "source": [
        "lstm_units = 256\n",
        "num_of_classes = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw82-Hw_N27O"
      },
      "source": [
        "class CNN_LSTM(tf.keras.Model):\n",
        "    def __init__(self, lstm_units, num_of_classes):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        self.lstm_units = lstm_units\n",
        "        # Initialize inceptionV3\n",
        "        self.inceptionV3 = tf.keras.applications.InceptionV3(\n",
        "            input_shape=(image_dims[0], image_dims[1], 3), include_top=False, weights='imagenet', pooling='avg')\n",
        "        self.inceptionV3.trainable = False\n",
        "        \n",
        "        # Define LSTM\n",
        "        self.lstm_1 = tf.keras.layers.LSTM(\n",
        "            lstm_units, \n",
        "            return_state=True,\n",
        "            recurrent_initializer='glorot_uniform')\n",
        "        \n",
        "        self.fc = tf.keras.layers.Dense(num_of_classes)\n",
        "\n",
        "    def call(self, x, hidden_state, cell_state):\n",
        "        # x (batch size, 16, image_dims[0], image_dims[1], 3)\n",
        "        # hidden_state (batch size, lstm_units)\n",
        "        # cell_state (batch size, lstm_units)\n",
        "        for i in range(0, x.shape[1]):\n",
        "            # x[:, i, :, :, :] # (batch size, image_dims[0], image_dims[1], 3)\n",
        "            out = self.inceptionV3(x[:, i, :, :, :]) # (batch size, 1, 2048)\n",
        "            out = tf.expand_dims(out, 1)\n",
        "            _, hidden_state, cell_state = self.lstm_1(\n",
        "                out, initial_state=[hidden_state, cell_state])\n",
        "            \n",
        "\n",
        "        # Pass the last hidden state\n",
        "        output = self.fc(hidden_state) # (batch size, num_of_classes)\n",
        "\n",
        "        return output\n",
        "  \n",
        "    def initialize_state(self, batch_size):\n",
        "        return tf.zeros((batch_size, self.lstm_units)), tf.zeros((batch_size, self.lstm_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHvI1relOIsk"
      },
      "source": [
        "cnn_lstm = CNN_LSTM(lstm_units, num_of_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1KNI911OO1I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9ab49b7-e371-4f95-caa7-871e15cc796b"
      },
      "source": [
        "# Load model weights\n",
        "cnn_lstm.load_weights('<Path to model weights>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f02fedf2080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPTFu75HOVPr"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU7y522dOdmu"
      },
      "source": [
        "def evaluate(x):\n",
        "    # Get intial hidden state and cell state\n",
        "    hidden_state, cell_state = cnn_lstm.initialize_state(x.shape[0])\n",
        "    # Predict\n",
        "    predictions = cnn_lstm(x, hidden_state, cell_state)\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqF-7O-9Oeea"
      },
      "source": [
        "predictions = evaluate(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_56pL8IDO4U8"
      },
      "source": [
        "#### Take average of 10 predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV2I36h1O8D2"
      },
      "source": [
        "final_output = tf.reduce_sum(tf.argmax(predictions, axis=1)) / 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyNJ6jmGPZFv"
      },
      "source": [
        "#### Apply thresholding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW00rltxPMn2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d60856fa-a621-4d92-e697-cb6203ff6dc7"
      },
      "source": [
        "if final_output >= 0.5:\n",
        "    print('Final output is Cheating')\n",
        "else:\n",
        "    print('Final output is Not Cheating')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final output is Not Cheating\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZShJc1cIgqM"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}